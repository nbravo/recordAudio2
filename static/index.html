<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8" />
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <script src="https://www.webrtc-experiment.com/RecordRTC.js"> </script>
        <script src="jquery.js"></script>
        <script src="chroma.js"></script>
    </head>
    <body>
      <h1> Spectrogram Demo</h1>

      <section class="experiment">
        <div id="container_div">
          <div class="left_div">
            <h2>Step 1 (Optional):<br>Set STFT Parameters</h2>
            FFT Size:<br>
            The size of the FFT used for frequency-domain analysis.<br>
            <select id="fftSizeDropDown">
              <option>32</option>
              <option>64</option>
              <option>128</option>
              <option>256</option>
              <option>512</option>
              <option>1024</option>
              <option>2048</option>
            </select>
            <br>
            <br>
            <br>
            Buffer Size:<br>
            Determines the buffer size in units of sample-frame.<br>
            <select id="sampleSizeDropDown">
              <option>256</option>
              <option>512</option>
              <option>1024</option>
              <option>2048</option>
              <option>4096</option>
              <option>8192</option>
              <option>16384</option>
            </select>
            <br>
            <br>
            <br>
            Smoothing Time Constant:<br>
            A value from 0 -> 1 where 0 represents no time averaging<br> with the last analysis frame.<br>
            <input id="smoothingTimeConstant" type="text">
            <br><br>
            <input id="parametersButton" type="button" value="Set Parameters">

          </div>

          <div class="right_div">
            <h2 class="header">
              Step 2: Record Audio
            </h2>
            <audio id="audio" controls="controls"></audio>
            <button id="start-recording">Record</button>
            <button id="stop-recording" disabled="disabled">Stop</button>
            <h2 id="audio-url-preview"></h2>
          </div>
        </div>
      </section>

      <div>
        <h3>Step 3: Examine Spectrogram</h3>
        <canvas id="canvas" width="800" height="256"></canvas>
      </div>

        <p id="controls">
          <input type="button" id="stop_button" value="Stop">
        </p>
        <style>
        #canvas {
          margin-left: auto;
          margin-right: auto;
          display: block;
          background-color: black;
        }

        #controls {
          text-align: center;
        }

        #container_div {
            width: 100%;
            border: 1px solid red;
            margin-right: 10px;
            float: left;
        }

        .right_div {
          float: right;
          margin-right: 80px;
        }

        .left_div {
            float: left;
            margin-left: 80px;
            margin-right: 5px;
        }

        #start_button, #stop_button {
          font-size: 16pt;
        }
        </style>
        <script>
            var sampleSize = 1024; // number of samples to collect before analyzing FFT
            var fftSize = 1024; // must be power of two
            var smoothingTimeConstant = 0.0;

            // fetching DOM references
            var startRecording = document.querySelector('#start-recording');
            var stopRecording  = document.querySelector('#stop-recording');
            var audioElement = document.querySelector('#audio');
            var sampleSizeElement = $('#sampleSizeDropDown');
            var smoothingTimeConstantElement = $('#smoothingTimeConstant');
            var fftSizeElement = $('#fftSizeDropDown');
            var parametersButtonElement = $('#parametersButton');

            // set parameter defaults
            sampleSizeElement.val(sampleSize);
            fftSizeElement.val(fftSize);
            smoothingTimeConstantElement.val(smoothingTimeConstant);

            // global variables
            var currentBrowser = !!navigator.mozGetUserMedia ? 'gecko' : 'chromium';

            var fileName;
            var audioRecorder;

            // Global Variables for Audio
            var audioContext;
            var audioBuffer;
            var sourceNode;
            var analyserNode;
            var javascriptNode;
            var audioData = null;
            var audioPlaying = false;
            var frequencyArray; // array to hold frequency data
            var audioUrl;

            // Global Variables for Drawing
            var column = 0;
            var canvasWidth = 800;
            var canvasHeight = 256;
            var ctx;

            // reusable helpers
            var createSpectrogram = function() {
              column = 0;
              // Set up / reset the audio Analyser and Source Buffer
              setupAudioNodes();
              // setup the event handler that is triggered every time enough samples have been collected
              // trigger the audio analysis and draw one column in the display based on the results
              javascriptNode.onaudioprocess = function () {
                // get the Frequency Domain data for this sample
                analyserNode.getByteFrequencyData(frequencyArray);
                // draw one column of the spectrogram if the audio is playing
                if (audioPlaying == true) {
                  requestAnimFrame(drawSpectrogram);
                }
              }
              loadSound(audioUrl);
            }

            // this function submits both audio/video or single recorded blob to nodejs server
            function postFiles(audio) {
                // getting unique identifier for the file name
                fileName = generateRandomString();

                // this object is used to allow submitting multiple recorded blobs
                var files = { };

                // recorded audio blob
                files.audio = {
                    name: fileName + '.' + audio.blob.type.split('/')[1],
                    type: audio.blob.type,
                    contents: audio.dataURL
                };

                files.uploadOnlyAudio = true;

                audioElement.src = '';

                xhr('/upload', JSON.stringify(files), function(_fileName) {
                    var href = location.href.substr(0, location.href.lastIndexOf('/') + 1);
                    var currUrl = href + 'uploads/' + _fileName;
                    audioUrl = currUrl;
                    audioElement.src = currUrl;
                    audioElement.muted = false;
                    audioElement.controls = true;
                    createSpectrogram();
                });

                if (mediaStream) mediaStream.stop();
            }

            // XHR2/FormData
            function xhr(url, data, callback) {
                var request = new XMLHttpRequest();
                request.onreadystatechange = function() {
                    if (request.readyState == 4 && request.status == 200) {
                        callback(request.responseText);
                    }
                };

                request.open('POST', url);
                request.send(data);
            }

            // generating random string
            function generateRandomString() {
                if (window.crypto) {
                    var a = window.crypto.getRandomValues(new Uint32Array(3)),
                        token = '';
                    for (var i = 0, l = a.length; i < l; i++) token += a[i].toString(36);
                    return token;
                } else {
                    return (Math.random() * new Date().getTime()).toString(36).replace( /\./g , '');
                }
            }

            // when stopRecording is clicked
            function onStopRecording() {
                audioRecorder.getDataURL(function(audioDataURL) {
                    var audio = {
                        blob: audioRecorder.getBlob(),
                        dataURL: audioDataURL
                    };

                    postFiles(audio);
                });
            }

            var mediaStream = null;
            // reusable getUserMedia
            function captureUserMedia(success_callback) {
                var session = {
                    audio: true,
                    video: false
                };

                navigator.getUserMedia(session, success_callback, function(error) {
                    alert( JSON.stringify(error) );
                });
            }

            // UI events handling
            startRecording.onclick = function() {
                startRecording.disabled = true;

                captureUserMedia(function(stream) {
                    mediaStream = stream;

                    audioElement.src = window.URL.createObjectURL(stream);
                    audioElement.play();
                    audioElement.muted = true;
                    audioElement.controls = false;

                    // it is second parameter of the RecordRTC
                    var audioConfig = {};

                    audioRecorder = RecordRTC(stream, audioConfig);

                    audioRecorder.startRecording();

                    // enable stop-recording button
                    stopRecording.disabled = false;
                });
            };

            stopRecording.onclick = function() {
                startRecording.disabled = false;
                stopRecording.disabled = true;

                audioRecorder.stopRecording(onStopRecording);

            };

            parametersButton.onclick = function() {
                fftSize = parseInt(fftSizeElement.val());
                sampleSize = parseInt(sampleSizeElement.val());

              if (!isNaN(parseFloat(smoothingTimeConstantElement.val()))) {
                smoothingTimeConstant = parseFloat(smoothingTimeConstantElement.val());
              } else {
                smoothingTimeConstantElement.val(smoothingTimeConstant);
              }
            };

            window.onbeforeunload = function() {
                startRecording.disabled = false;
            };

            // Hacks to deal with different function names in different browsers
              window.requestAnimFrame = (function() {
                return window.requestAnimationFrame ||
                window.webkitRequestAnimationFrame ||
                window.mozRequestAnimationFrame ||
                function(callback, element) {
                  window.setTimeout(callback, 1000 / 60);
                };
              })();

              window.AudioContext = (function(){
                return window.webkitAudioContext || window.AudioContext || window.mozAudioContext;
              })();


              // Uses the chroma.js library by Gregor Aisch to create a color gradient
              // download from https://github.com/gka/chroma.js
              var colorScale = new chroma.scale(['black', 'red', 'yellow', 'white']).out('hex');
              $(document).ready(function() {
                // get the context from the canvas to draw on
                ctx = $("#canvas").get()[0].getContext("2d");

                // the AudioContext is the primary 'container' for all your audio node objects
                try {
                  audioContext = new AudioContext();
                } catch(e) {
                  alert('Web Audio API is not supported in this browser');
                }

                // When the Start button is clicked, finish setting up the audio nodes, play the sound and
                // gather samples for FFT frequency analysis, draw the spectrogram

                // Stop the audio playing
                $("#stop_button").click(function(e) {
                  e.preventDefault();
                  sourceNode.stop(0);
                  audioPlaying = false;
                });
              });

              function setupAudioNodes() {
                sourceNode = audioContext.createBufferSource();
                analyserNode = audioContext.createAnalyser();
                analyserNode.smoothingTimeConstant = smoothingTimeConstant;
                analyserNode.fftSize = fftSize;
                console.log(fftSize);
                javascriptNode = audioContext.createScriptProcessor(sampleSize, 1, 1);

                // Create the array for the data values
                frequencyArray = new Uint8Array(analyserNode.frequencyBinCount);

                // Now connect the nodes together
                sourceNode.connect(audioContext.destination);
                sourceNode.connect(analyserNode);
                analyserNode.connect(javascriptNode);
                javascriptNode.connect(audioContext.destination);
              }

              // Load the sound from the URL only once and store it in global variable audioData
              function loadSound(url) {
                var request = new XMLHttpRequest();
                request.open('GET', url, true);
                request.responseType = 'arraybuffer';
                // When loaded, decode the data and play the sound
                request.onload = function () {
                  audioContext.decodeAudioData(request.response, function (buffer) {
                    audioData = buffer;
                    playSound(audioData);
                  }, onError);
                }
                request.send();
              }

              // Play the sound with no delay and loop over the sample until stopped
              function playSound(buffer) {
                sourceNode.buffer = buffer;
                sourceNode.start(0); // Play the sound now
                sourceNode.loop = true;
                audioPlaying = true;
              }

              function onError(e) {
                console.log(e);
              }

              // Draw the Spectrogram from the frequency array
              // The array has 512 elements - but truncate at 256
              function drawSpectrogram() {
                for (var i = 0; i < frequencyArray.length; i++) {
                  // Get the color from the color map, draw 1x1 pixel rectangle
                  ctx.fillStyle = colorScale(frequencyArray[i] / 256.0);
                  ctx.fillRect(column,canvasHeight - i, 1, 1);
                }
                // loop around the canvas when we reach the end
                column += 1;
                if (column >= canvasWidth) {
                  column = 0;
                  clearCanvas();
                }
              }

              function clearCanvas() {
                ctx.clearRect(0, 0, canvasWidth, canvasHeight);
              }
        </script>
    </body>
</html>
